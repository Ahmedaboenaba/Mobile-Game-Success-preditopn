{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a03e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c85549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (Replace with your actual file paths)\n",
    "train = pd.read_csv('/kaggle/input/predicting-mobile-game-success/predicting_mobile_game_success_train_set.csv')\n",
    "test = pd.read_csv('/kaggle/input/test-set/samples_mobile_game_success_test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "508c6bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:52: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:52: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_676/3751179120.py:52: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Age_Rating_Num'] = df['Age Rating'].str.extract('(\\d+)').astype(float)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. PREPROCESSING & FEATURE ENGINEERING FUNCTION ---\n",
    "def process_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- A. Date Management ---\n",
    "    # Convert to datetime\n",
    "    df['Original Release Date'] = pd.to_datetime(df['Original Release Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    df['Current Version Release Date'] = pd.to_datetime(df['Current Version Release Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    \n",
    "    # Create \"Age\" features (Reference date: use max date in dataset or today)\n",
    "    ref_date = datetime.now()\n",
    "    df['App_Age_Days'] = (ref_date - df['Original Release Date']).dt.days\n",
    "    df['Days_Since_Update'] = (ref_date - df['Current Version Release Date']).dt.days\n",
    "    df['Update_Lag'] = (df['Current Version Release Date'] - df['Original Release Date']).dt.days\n",
    "    \n",
    "    # --- B. List & String Parsing ---\n",
    "    \n",
    "    # Languages: Count number of languages supported\n",
    "    df['Lang_Count'] = df['Languages'].apply(lambda x: len(str(x).split(',')) if pd.notnull(x) else 0)\n",
    "    \n",
    "    # Genres: Count number of genres\n",
    "    df['Genre_Count'] = df['Genres'].apply(lambda x: len(str(x).split(',')) if pd.notnull(x) else 0)\n",
    "    \n",
    "    # In-app Purchases: Extract Min, Max, and Mean prices\n",
    "    def extract_iap_stats(iap_str):\n",
    "        if pd.isnull(iap_str) or iap_str == []:\n",
    "            return 0, 0, 0, 0\n",
    "        try:\n",
    "            # Assuming format is like \"1.99, 2.99, 0.99\"\n",
    "            prices = [float(p.strip()) for p in str(iap_str).split(',')]\n",
    "            return len(prices), np.mean(prices), np.max(prices), np.min(prices)\n",
    "        except:\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "    iap_stats = df['In-app Purchases'].apply(extract_iap_stats)\n",
    "    df['IAP_Count'] = iap_stats.apply(lambda x: x[0])\n",
    "    df['IAP_Mean'] = iap_stats.apply(lambda x: x[1])\n",
    "    df['IAP_Max'] = iap_stats.apply(lambda x: x[2])\n",
    "    \n",
    "    # --- C. Text Meta-Features ---\n",
    "    # Length of Description, Name, Subtitle (Longer descriptions often mean better SEO)\n",
    "    df['Desc_Len'] = df['Description'].fillna('').apply(len)\n",
    "    df['Name_Len'] = df['Name'].fillna('').apply(len)\n",
    "    df['Subtitle_Len'] = df['Subtitle'].fillna('').apply(len)\n",
    "    \n",
    "    # --- D. Numerical Transforms ---\n",
    "    # Size is usually huge (bytes), log transform normalizes it\n",
    "    df['Size_Log'] = np.log1p(df['Size'])\n",
    "    \n",
    "    # --- E. Categorical Encoding ---\n",
    "    # Simplified Age Rating (extract number)\n",
    "    df['Age_Rating_Num'] = df['Age Rating'].str.extract('(\\d+)').astype(float)\n",
    "    \n",
    "    # Factorize Primary Genre (Turn string into ID)\n",
    "    df['Primary_Genre_Code'] = pd.factorize(df['Primary Genre'])[0]\n",
    "    \n",
    "    # Drop unused or raw columns\n",
    "    drop_cols = ['ID', 'Name', 'Subtitle', 'In-app Purchases', 'Description', \n",
    "                 'Developer', 'Languages', 'Size', 'Genres', 'Original Release Date', \n",
    "                 'Current Version Release Date', 'Age Rating', 'Primary Genre', 'URL', 'Icon URL','Unnamed: 18']\n",
    "    \n",
    "    # Keep only columns that exist (to avoid errors if cols are missing)\n",
    "    cols_to_drop = [c for c in drop_cols if c in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e50504d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL', 'ID', 'Name', 'Subtitle', 'Icon URL', 'Average User Rating',\n",
       "       'User Rating Count', 'Price', 'In-app Purchases', 'Description',\n",
       "       'Developer', 'Age Rating', 'Languages', 'Size', 'Primary Genre',\n",
       "       'Genres', 'Original Release Date', 'Current Version Release Date',\n",
       "       'Unnamed: 18'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c941fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. EXECUTION ---\n",
    "train= train.drop_duplicates()\n",
    "df_train = train.copy()\n",
    "df_train = df_train[df_train['Average User Rating'].notna()]\n",
    "df_test = test.copy()\n",
    "\n",
    "# Separate Target\n",
    "target = 'Average User Rating'\n",
    "y = df_train[target]\n",
    "X = df_train.drop(columns=[target])\n",
    "\n",
    "# Process Data\n",
    "X_processed = process_data(X)\n",
    "test_processed = process_data(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19611695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6453, 16), (6453,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca47024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6453 entries, 0 to 13597\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   User Rating Count   6453 non-null   float64\n",
      " 1   Price               6453 non-null   float64\n",
      " 2   App_Age_Days        6453 non-null   int64  \n",
      " 3   Days_Since_Update   6453 non-null   int64  \n",
      " 4   Update_Lag          6453 non-null   int64  \n",
      " 5   Lang_Count          6453 non-null   int64  \n",
      " 6   Genre_Count         6453 non-null   int64  \n",
      " 7   IAP_Count           6453 non-null   int64  \n",
      " 8   IAP_Mean            6453 non-null   float64\n",
      " 9   IAP_Max             6453 non-null   float64\n",
      " 10  Desc_Len            6453 non-null   int64  \n",
      " 11  Name_Len            6453 non-null   int64  \n",
      " 12  Subtitle_Len        6453 non-null   int64  \n",
      " 13  Size_Log            6453 non-null   float64\n",
      " 14  Age_Rating_Num      6453 non-null   float64\n",
      " 15  Primary_Genre_Code  6453 non-null   int64  \n",
      "dtypes: float64(6), int64(10)\n",
      "memory usage: 857.0 KB\n"
     ]
    }
   ],
   "source": [
    "X_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b056073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-12 22:31:46,592] A new study created in memory with name: no-name-e5dd647b-d345-41b2-85b3-9a86c1cd70ec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optimization... (This might take 5-10 mins)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-12 22:31:49,465] Trial 0 finished with value: 0.825884544727197 and parameters: {'n_estimators': 1327, 'learning_rate': 0.07146672552192151, 'max_depth': 4, 'subsample': 0.856941526529625, 'colsample_bytree': 0.8272619625768358, 'reg_alpha': 0.028247548069526042, 'reg_lambda': 3.293614017870211e-08}. Best is trial 0 with value: 0.825884544727197.\n",
      "[I 2026-02-12 22:32:01,393] Trial 1 finished with value: 0.7698001650142107 and parameters: {'n_estimators': 918, 'learning_rate': 0.09201683503152455, 'max_depth': 10, 'subsample': 0.7175874000277433, 'colsample_bytree': 0.7704577830123465, 'reg_alpha': 2.8662580037508315e-08, 'reg_lambda': 1.505688331889684}. Best is trial 1 with value: 0.7698001650142107.\n",
      "[I 2026-02-12 22:32:10,189] Trial 2 finished with value: 0.7832749955374924 and parameters: {'n_estimators': 691, 'learning_rate': 0.08552195261158697, 'max_depth': 9, 'subsample': 0.8261557445004611, 'colsample_bytree': 0.8118844754695834, 'reg_alpha': 0.021406661641401727, 'reg_lambda': 0.0008291798189677032}. Best is trial 1 with value: 0.7698001650142107.\n",
      "[I 2026-02-12 22:32:11,616] Trial 3 finished with value: 0.7563871542176822 and parameters: {'n_estimators': 662, 'learning_rate': 0.024567003077890944, 'max_depth': 4, 'subsample': 0.7988762777568308, 'colsample_bytree': 0.7779111356169005, 'reg_alpha': 0.02735301483086613, 'reg_lambda': 3.792508882237509e-08}. Best is trial 3 with value: 0.7563871542176822.\n",
      "[I 2026-02-12 22:32:18,449] Trial 4 finished with value: 0.7853494634819637 and parameters: {'n_estimators': 971, 'learning_rate': 0.04123870376401331, 'max_depth': 7, 'subsample': 0.688225304183927, 'colsample_bytree': 0.9690810486243436, 'reg_alpha': 1.20862314753057e-08, 'reg_lambda': 0.0001956700708093119}. Best is trial 3 with value: 0.7563871542176822.\n",
      "[I 2026-02-12 22:32:28,869] Trial 5 finished with value: 0.7830841473145478 and parameters: {'n_estimators': 926, 'learning_rate': 0.05801615372889882, 'max_depth': 9, 'subsample': 0.7727528571063231, 'colsample_bytree': 0.7840028234693968, 'reg_alpha': 2.5969889441596915e-06, 'reg_lambda': 0.34824938244125714}. Best is trial 3 with value: 0.7563871542176822.\n",
      "[I 2026-02-12 22:32:31,605] Trial 6 finished with value: 0.8221655379039944 and parameters: {'n_estimators': 938, 'learning_rate': 0.09530082645226358, 'max_depth': 5, 'subsample': 0.7533343884350019, 'colsample_bytree': 0.7188110239543455, 'reg_alpha': 8.738448570788662e-08, 'reg_lambda': 2.2999558092020615e-06}. Best is trial 3 with value: 0.7563871542176822.\n",
      "[I 2026-02-12 22:32:35,133] Trial 7 finished with value: 0.7888050419895608 and parameters: {'n_estimators': 1299, 'learning_rate': 0.03483439448984418, 'max_depth': 5, 'subsample': 0.8705878204456301, 'colsample_bytree': 0.6522759831892831, 'reg_alpha': 0.0012631806372899275, 'reg_lambda': 0.007331605657013601}. Best is trial 3 with value: 0.7563871542176822.\n",
      "[I 2026-02-12 22:32:39,101] Trial 8 finished with value: 0.8645858148158289 and parameters: {'n_estimators': 1889, 'learning_rate': 0.0987088773660705, 'max_depth': 4, 'subsample': 0.6765140509784919, 'colsample_bytree': 0.8127770097640459, 'reg_alpha': 2.322228380871538e-08, 'reg_lambda': 0.0814682448509796}. Best is trial 3 with value: 0.7563871542176822.\n",
      "[I 2026-02-12 22:32:41,541] Trial 9 finished with value: 0.7819892934097042 and parameters: {'n_estimators': 1109, 'learning_rate': 0.0873368565498381, 'max_depth': 4, 'subsample': 0.7643653877013488, 'colsample_bytree': 0.8120214486826393, 'reg_alpha': 1.384565455163976, 'reg_lambda': 0.00014459724147333866}. Best is trial 3 with value: 0.7563871542176822.\n",
      "[I 2026-02-12 22:32:44,812] Trial 10 finished with value: 0.735674765144691 and parameters: {'n_estimators': 530, 'learning_rate': 0.005064352478859401, 'max_depth': 7, 'subsample': 0.9726789922792863, 'colsample_bytree': 0.9052902927647877, 'reg_alpha': 7.998228427249704, 'reg_lambda': 1.5237184116576743e-08}. Best is trial 10 with value: 0.735674765144691.\n",
      "[I 2026-02-12 22:32:48,405] Trial 11 finished with value: 0.7339744629937727 and parameters: {'n_estimators': 584, 'learning_rate': 0.006671349652208579, 'max_depth': 7, 'subsample': 0.9748445200398398, 'colsample_bytree': 0.9237384669421154, 'reg_alpha': 6.360719721858602, 'reg_lambda': 1.836328077600074e-08}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:32:52,035] Trial 12 finished with value: 0.7355015814839615 and parameters: {'n_estimators': 594, 'learning_rate': 0.0069188599129048345, 'max_depth': 7, 'subsample': 0.9623606812055282, 'colsample_bytree': 0.9390304566000743, 'reg_alpha': 8.281434061944925, 'reg_lambda': 1.5084689013858108e-06}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:33:08,035] Trial 13 finished with value: 0.7594275230717565 and parameters: {'n_estimators': 1644, 'learning_rate': 0.007453265509742043, 'max_depth': 8, 'subsample': 0.9877274426504278, 'colsample_bytree': 0.9963472755665186, 'reg_alpha': 0.33768444097556527, 'reg_lambda': 1.7100530584694686e-06}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:33:10,447] Trial 14 finished with value: 0.7519193376993122 and parameters: {'n_estimators': 509, 'learning_rate': 0.01876442794488576, 'max_depth': 6, 'subsample': 0.9236988746789674, 'colsample_bytree': 0.9167949164095591, 'reg_alpha': 5.935023897572751e-05, 'reg_lambda': 1.5684796100307888e-06}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:33:13,872] Trial 15 finished with value: 0.7397081402399713 and parameters: {'n_estimators': 747, 'learning_rate': 0.01918082245975436, 'max_depth': 6, 'subsample': 0.9238711410268218, 'colsample_bytree': 0.9149865840922292, 'reg_alpha': 8.835160795622008, 'reg_lambda': 9.856874865473999e-06}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:33:27,175] Trial 16 finished with value: 0.7628578696622913 and parameters: {'n_estimators': 1525, 'learning_rate': 0.033422904046136646, 'max_depth': 8, 'subsample': 0.9284105829214399, 'colsample_bytree': 0.8755897862977595, 'reg_alpha': 0.4895852638632451, 'reg_lambda': 4.836476279906322e-07}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:33:34,561] Trial 17 finished with value: 0.7879970960082461 and parameters: {'n_estimators': 778, 'learning_rate': 0.05252630249180021, 'max_depth': 8, 'subsample': 0.9950626353305607, 'colsample_bytree': 0.9580145696127292, 'reg_alpha': 0.001349920301158836, 'reg_lambda': 2.2594925996594506e-07}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:33:41,511] Trial 18 finished with value: 0.7641556352473725 and parameters: {'n_estimators': 1144, 'learning_rate': 0.013223228146066385, 'max_depth': 7, 'subsample': 0.6317597232103721, 'colsample_bytree': 0.8649687906914255, 'reg_alpha': 0.00013476174153431784, 'reg_lambda': 4.396332094528502e-05}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:33:43,987] Trial 19 finished with value: 0.7595604259200287 and parameters: {'n_estimators': 505, 'learning_rate': 0.028183223580273566, 'max_depth': 6, 'subsample': 0.8769639994425626, 'colsample_bytree': 0.9488301894174788, 'reg_alpha': 0.1565407391046064, 'reg_lambda': 1.565020064033897e-07}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:33:45,101] Trial 20 finished with value: 0.7919487000941174 and parameters: {'n_estimators': 773, 'learning_rate': 0.04609792572502397, 'max_depth': 3, 'subsample': 0.9522937001563634, 'colsample_bytree': 0.6140692733647924, 'reg_alpha': 5.699445167661885e-06, 'reg_lambda': 1.774323185431617e-05}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:33:48,888] Trial 21 finished with value: 0.7365991362067557 and parameters: {'n_estimators': 592, 'learning_rate': 0.01214283981864693, 'max_depth': 7, 'subsample': 0.9639147612989621, 'colsample_bytree': 0.900289414979816, 'reg_alpha': 4.436838128926688, 'reg_lambda': 1.9105977200076122e-08}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:33:52,459] Trial 22 finished with value: 0.735295054827802 and parameters: {'n_estimators': 625, 'learning_rate': 0.006456165878199057, 'max_depth': 7, 'subsample': 0.9998423526031567, 'colsample_bytree': 0.8696412932943631, 'reg_alpha': 7.114985611901832, 'reg_lambda': 9.299354144311553e-08}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:34:00,407] Trial 23 finished with value: 0.749504829760411 and parameters: {'n_estimators': 836, 'learning_rate': 0.017245627184759124, 'max_depth': 8, 'subsample': 0.9032062453911356, 'colsample_bytree': 0.9411729586702557, 'reg_alpha': 1.3643952543008098, 'reg_lambda': 1.771806117115593e-07}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:34:09,669] Trial 24 finished with value: 0.745706986205603 and parameters: {'n_estimators': 646, 'learning_rate': 0.00595382763929958, 'max_depth': 9, 'subsample': 0.9581795996048519, 'colsample_bytree': 0.8619606516533871, 'reg_alpha': 0.11179101951147209, 'reg_lambda': 8.385432730975194e-08}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:34:14,355] Trial 25 finished with value: 0.7556945461278665 and parameters: {'n_estimators': 1051, 'learning_rate': 0.023404973402181135, 'max_depth': 6, 'subsample': 0.9966171842497672, 'colsample_bytree': 0.8537882767549345, 'reg_alpha': 1.47737427878541, 'reg_lambda': 4.29736679080217e-06}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:34:16,392] Trial 26 finished with value: 0.7425737558478716 and parameters: {'n_estimators': 633, 'learning_rate': 0.06753378368911242, 'max_depth': 5, 'subsample': 0.8969527372518119, 'colsample_bytree': 0.9986223609986551, 'reg_alpha': 9.742645641301761, 'reg_lambda': 6.342193833417052e-07}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:34:27,863] Trial 27 finished with value: 0.778690871584935 and parameters: {'n_estimators': 1948, 'learning_rate': 0.029338399083457277, 'max_depth': 7, 'subsample': 0.9396978650030469, 'colsample_bytree': 0.8894662436038281, 'reg_alpha': 0.006530080670464236, 'reg_lambda': 0.0017687284391759493}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:34:36,133] Trial 28 finished with value: 0.7469271964733951 and parameters: {'n_estimators': 849, 'learning_rate': 0.012718588326210856, 'max_depth': 8, 'subsample': 0.8345375579469039, 'colsample_bytree': 0.9331501797892434, 'reg_alpha': 1.339528998348952, 'reg_lambda': 1.5711988911181758e-08}. Best is trial 11 with value: 0.7339744629937727.\n",
      "[I 2026-02-12 22:34:42,482] Trial 29 finished with value: 0.7676424948565247 and parameters: {'n_estimators': 1413, 'learning_rate': 0.038617448691828364, 'max_depth': 6, 'subsample': 0.8443728909408743, 'colsample_bytree': 0.8433523382240472, 'reg_alpha': 0.08547706324711625, 'reg_lambda': 9.862125392967918}. Best is trial 11 with value: 0.7339744629937727.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------\n",
      "ðŸŽ‰ BEST RMSE FOUND: 0.7339744629937727\n",
      "ðŸ‘‰ COPY THESE PARAMS FOR SCRIPT 3:\n",
      "{'n_estimators': 584, 'learning_rate': 0.006671349652208579, 'max_depth': 7, 'subsample': 0.9748445200398398, 'colsample_bytree': 0.9237384669421154, 'reg_alpha': 6.360719721858602, 'reg_lambda': 1.836328077600074e-08}\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# fine tuning parameters for better performance\n",
    "\n",
    "import optuna\n",
    "import re\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "# Basic Preprocessing\n",
    "def simple_process(df):\n",
    "    df['Size_Log'] = np.log1p(df['Size'])\n",
    "    df['Desc_Len'] = df['Description'].fillna('').apply(len)\n",
    "    df['Lang_Count'] = df['Languages'].apply(lambda x: len(str(x).split(',')) if pd.notnull(x) else 0)\n",
    "    \n",
    "    # Date Engineering\n",
    "    df['Original Release Date'] = pd.to_datetime(df['Original Release Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    df['Current Version Release Date'] = pd.to_datetime(df['Current Version Release Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    ref_date = pd.to_datetime('today')\n",
    "    df['Days_Since_Update'] = (ref_date - df['Current Version Release Date']).dt.days\n",
    "    df['App_Age_Days'] = (ref_date - df['Original Release Date']).dt.days\n",
    "    \n",
    "    # Select only numeric\n",
    "    df = df.select_dtypes(include=['number', 'bool'])\n",
    "    df = df.rename(columns = lambda x: re.sub('[^A-Za-z0-9_]+', '', x)) # Clean names\n",
    "    return df.fillna(0)\n",
    "\n",
    "X = simple_process(df_train.drop(columns=['Average User Rating']))\n",
    "y = df_train['Average User Rating']\n",
    "\n",
    "# --- 2. OPTUNA OPTIMIZATION ---\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(**param)\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring='neg_root_mean_squared_error')\n",
    "    return -scores.mean()\n",
    "\n",
    "print(\"Starting Optimization... (This might take 5-10 mins)\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"ðŸŽ‰ BEST RMSE FOUND:\", study.best_value)\n",
    "print(\"ðŸ‘‰ COPY THESE PARAMS FOR SCRIPT 3:\")\n",
    "print(study.best_params)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af3ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. MODELING (Ensemble) ---\n",
    "\n",
    "# Initialize Models\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=1000, \n",
    "    learning_rate=0.01, \n",
    "    max_depth=3, \n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# Ensemble Voting Regressor (Averages the predictions of both)\n",
    "ensemble = VotingRegressor([('xgb', xgb), ('lgbm', lgbm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8b71f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 0.7165\n"
     ]
    }
   ],
   "source": [
    "# --- 4. VALIDATION ---\n",
    "# Use Cross-Validation to get a realistic RMSE\n",
    "scores = cross_val_score(ensemble, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Average RMSE: {-scores.mean():.4f}\")\n",
    "\n",
    "# --- 5. FINAL TRAINING & SUBMISSION ---\n",
    "ensemble.fit(X_processed, y)\n",
    "preds = ensemble.predict(test_processed)\n",
    "\n",
    "# Post-processing: Clip predictions to be between 0 and 5\n",
    "preds = np.clip(preds, 0.0, 5.0)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': preds})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72d4106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average RMSE: 0.7146\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=1000,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "scores_rf = cross_val_score(rf_model, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Random Forest Average RMSE: {-scores_rf.mean():.4f}\")\n",
    "\n",
    "rf_model.fit(X_processed, y)\n",
    "rf_preds = rf_model.predict(test_processed)\n",
    "rf_preds = np.clip(rf_preds, 0.0, 5.0)\n",
    "submission_rf = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': rf_preds})\n",
    "submission_rf.to_csv('submission_rf.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e8a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average RMSE: 0.7150\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=3000,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "scores_rf = cross_val_score(rf_model, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Random Forest Average RMSE: {-scores_rf.mean():.4f}\")\n",
    "\n",
    "rf_model.fit(X_processed, y)\n",
    "rf_preds = rf_model.predict(test_processed)\n",
    "rf_preds = np.clip(rf_preds, 0.0, 5.0)\n",
    "submission_rf = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': rf_preds})\n",
    "submission_rf.to_csv('submission_rf.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "785dbf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Average RMSE: 0.8329\n"
     ]
    }
   ],
   "source": [
    "# decisin tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_model = DecisionTreeRegressor(\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "scores_dt = cross_val_score(dt_model, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Decision Tree Average RMSE: {-scores_dt.mean():.4f}\")\n",
    "\n",
    "dt_model.fit(X_processed, y)\n",
    "dt_preds = dt_model.predict(test_processed)\n",
    "dt_preds = np.clip(dt_preds, 0.0, 5.0)\n",
    "submission_dt = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': dt_preds})\n",
    "submission_dt.to_csv('submission_dt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c972ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix Nans in test set\n",
    "test_processed = test_processed.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88d614a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Average RMSE: 0.7485\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "scores_svr = cross_val_score(svr_model, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"SVR Average RMSE: {-scores_svr.mean():.4f}\")\n",
    "svr_model.fit(X_processed, y)\n",
    "svr_preds = svr_model.predict(test_processed)\n",
    "svr_preds = np.clip(svr_preds, 0.0, 5.0)\n",
    "submission_svr = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': svr_preds})\n",
    "submission_svr.to_csv('submission_svr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b6431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Average RMSE: 0.7285\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "scores_lr = cross_val_score(lr_model, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Linear Regression Average RMSE: {-scores_lr.mean():.4f}\")\n",
    "lr_model.fit(X_processed, y)\n",
    "lr_preds = lr_model.predict(test_processed)\n",
    "lr_preds = np.clip(lr_preds, 0.0, 5.0)\n",
    "submission_lr = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': lr_preds})\n",
    "submission_lr.to_csv('submission_lr.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "972bd1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression Average RMSE: 5.5078\n"
     ]
    }
   ],
   "source": [
    "# polynomial regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3, interaction_only=True, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_processed)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "poly_model = LinearRegression()\n",
    "scores_poly = cross_val_score(poly_model, X_poly, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Polynomial Regression Average RMSE: {-scores_poly.mean():.4f}\")\n",
    "poly_model.fit(X_poly, y)\n",
    "test_poly = poly.transform(test_processed)\n",
    "poly_preds = poly_model.predict(test_poly)\n",
    "poly_preds = np.clip(poly_preds, 0.0, 5.0)\n",
    "submission_poly = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': poly_preds})\n",
    "submission_poly.to_csv('submission_poly.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd1b1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save modles in pickle format\n",
    "import pickle\n",
    "with open('xgb_model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb, f)\n",
    "with open('lgbm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lgbm, f)\n",
    "with open('rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "with open('dt_model.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_model, f)\n",
    "with open('svr_model.pkl', 'wb') as f:\n",
    "    pickle.dump(svr_model, f)\n",
    "with open('lr_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "with open('poly_model.pkl', 'wb') as f:\n",
    "    pickle.dump(poly_model, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
