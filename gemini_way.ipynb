{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a03e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "16c85549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (Replace with your actual file paths)\n",
    "train = pd.read_csv('/kaggle/input/predicting-mobile-game-success/predicting_mobile_game_success_train_set.csv')\n",
    "test = pd.read_csv('/kaggle/input/test-set/samples_mobile_game_success_test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "508c6bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:52: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:52: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_93/3751179120.py:52: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Age_Rating_Num'] = df['Age Rating'].str.extract('(\\d+)').astype(float)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. PREPROCESSING & FEATURE ENGINEERING FUNCTION ---\n",
    "def process_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- A. Date Management ---\n",
    "    # Convert to datetime\n",
    "    df['Original Release Date'] = pd.to_datetime(df['Original Release Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    df['Current Version Release Date'] = pd.to_datetime(df['Current Version Release Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    \n",
    "    # Create \"Age\" features (Reference date: use max date in dataset or today)\n",
    "    ref_date = datetime.now()\n",
    "    df['App_Age_Days'] = (ref_date - df['Original Release Date']).dt.days\n",
    "    df['Days_Since_Update'] = (ref_date - df['Current Version Release Date']).dt.days\n",
    "    df['Update_Lag'] = (df['Current Version Release Date'] - df['Original Release Date']).dt.days\n",
    "    \n",
    "    # --- B. List & String Parsing ---\n",
    "    \n",
    "    # Languages: Count number of languages supported\n",
    "    df['Lang_Count'] = df['Languages'].apply(lambda x: len(str(x).split(',')) if pd.notnull(x) else 0)\n",
    "    \n",
    "    # Genres: Count number of genres\n",
    "    df['Genre_Count'] = df['Genres'].apply(lambda x: len(str(x).split(',')) if pd.notnull(x) else 0)\n",
    "    \n",
    "    # In-app Purchases: Extract Min, Max, and Mean prices\n",
    "    def extract_iap_stats(iap_str):\n",
    "        if pd.isnull(iap_str) or iap_str == []:\n",
    "            return 0, 0, 0, 0\n",
    "        try:\n",
    "            # Assuming format is like \"1.99, 2.99, 0.99\"\n",
    "            prices = [float(p.strip()) for p in str(iap_str).split(',')]\n",
    "            return len(prices), np.mean(prices), np.max(prices), np.min(prices)\n",
    "        except:\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "    iap_stats = df['In-app Purchases'].apply(extract_iap_stats)\n",
    "    df['IAP_Count'] = iap_stats.apply(lambda x: x[0])\n",
    "    df['IAP_Mean'] = iap_stats.apply(lambda x: x[1])\n",
    "    df['IAP_Max'] = iap_stats.apply(lambda x: x[2])\n",
    "    \n",
    "    # --- C. Text Meta-Features ---\n",
    "    # Length of Description, Name, Subtitle (Longer descriptions often mean better SEO)\n",
    "    df['Desc_Len'] = df['Description'].fillna('').apply(len)\n",
    "    df['Name_Len'] = df['Name'].fillna('').apply(len)\n",
    "    df['Subtitle_Len'] = df['Subtitle'].fillna('').apply(len)\n",
    "    \n",
    "    # --- D. Numerical Transforms ---\n",
    "    # Size is usually huge (bytes), log transform normalizes it\n",
    "    df['Size_Log'] = np.log1p(df['Size'])\n",
    "    \n",
    "    # --- E. Categorical Encoding ---\n",
    "    # Simplified Age Rating (extract number)\n",
    "    df['Age_Rating_Num'] = df['Age Rating'].str.extract('(\\d+)').astype(float)\n",
    "    \n",
    "    # Factorize Primary Genre (Turn string into ID)\n",
    "    df['Primary_Genre_Code'] = pd.factorize(df['Primary Genre'])[0]\n",
    "    \n",
    "    # Drop unused or raw columns\n",
    "    drop_cols = ['ID', 'Name', 'Subtitle', 'In-app Purchases', 'Description', \n",
    "                 'Developer', 'Languages', 'Size', 'Genres', 'Original Release Date', \n",
    "                 'Current Version Release Date', 'Age Rating', 'Primary Genre', 'URL', 'Icon URL','Unnamed: 18']\n",
    "    \n",
    "    # Keep only columns that exist (to avoid errors if cols are missing)\n",
    "    cols_to_drop = [c for c in drop_cols if c in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e50504d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL', 'ID', 'Name', 'Subtitle', 'Icon URL', 'Average User Rating',\n",
       "       'User Rating Count', 'Price', 'In-app Purchases', 'Description',\n",
       "       'Developer', 'Age Rating', 'Languages', 'Size', 'Primary Genre',\n",
       "       'Genres', 'Original Release Date', 'Current Version Release Date',\n",
       "       'Unnamed: 18'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c941fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. EXECUTION ---\n",
    "train= train.drop_duplicates()\n",
    "df_train = train.copy()\n",
    "df_train = df_train[df_train['Average User Rating'].notna()]\n",
    "df_test = test.copy()\n",
    "\n",
    "# Separate Target\n",
    "target = 'Average User Rating'\n",
    "y = df_train[target]\n",
    "X = df_train.drop(columns=[target])\n",
    "\n",
    "# Process Data\n",
    "X_processed = process_data(X)\n",
    "test_processed = process_data(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c1a02819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train.copy()\n",
    "df_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "19611695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6453, 16), (6453,))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ca47024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6453 entries, 0 to 13597\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   User Rating Count   6453 non-null   float64\n",
      " 1   Price               6453 non-null   float64\n",
      " 2   App_Age_Days        6453 non-null   int64  \n",
      " 3   Days_Since_Update   6453 non-null   int64  \n",
      " 4   Update_Lag          6453 non-null   int64  \n",
      " 5   Lang_Count          6453 non-null   int64  \n",
      " 6   Genre_Count         6453 non-null   int64  \n",
      " 7   IAP_Count           6453 non-null   int64  \n",
      " 8   IAP_Mean            6453 non-null   float64\n",
      " 9   IAP_Max             6453 non-null   float64\n",
      " 10  Desc_Len            6453 non-null   int64  \n",
      " 11  Name_Len            6453 non-null   int64  \n",
      " 12  Subtitle_Len        6453 non-null   int64  \n",
      " 13  Size_Log            6453 non-null   float64\n",
      " 14  Age_Rating_Num      6453 non-null   float64\n",
      " 15  Primary_Genre_Code  6453 non-null   int64  \n",
      "dtypes: float64(6), int64(10)\n",
      "memory usage: 857.0 KB\n"
     ]
    }
   ],
   "source": [
    "X_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b056073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-12 19:48:24,646] A new study created in memory with name: no-name-68e82662-1f4f-40c4-99ea-ce99aac68912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optimization... (This might take 5-10 mins)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-12 19:48:30,575] Trial 0 finished with value: 0.7885087766116223 and parameters: {'n_estimators': 726, 'learning_rate': 0.05412887776206501, 'max_depth': 8, 'subsample': 0.6661567597116635, 'colsample_bytree': 0.7305662588633205, 'reg_alpha': 0.0001408669994207436, 'reg_lambda': 0.004376457076934193}. Best is trial 0 with value: 0.7885087766116223.\n",
      "[I 2026-02-12 19:48:36,047] Trial 1 finished with value: 0.7904591686666365 and parameters: {'n_estimators': 1698, 'learning_rate': 0.0290787033035153, 'max_depth': 5, 'subsample': 0.8406951281631386, 'colsample_bytree': 0.9296736502759168, 'reg_alpha': 4.288398270672664e-08, 'reg_lambda': 1.0404173394361729e-05}. Best is trial 0 with value: 0.7885087766116223.\n",
      "[I 2026-02-12 19:49:03,900] Trial 2 finished with value: 0.7769213264962144 and parameters: {'n_estimators': 1713, 'learning_rate': 0.03290168542566212, 'max_depth': 10, 'subsample': 0.7253062493594943, 'colsample_bytree': 0.8963578049772318, 'reg_alpha': 1.5637980873150723e-08, 'reg_lambda': 2.2915614561498962e-08}. Best is trial 2 with value: 0.7769213264962144.\n",
      "[I 2026-02-12 19:49:06,470] Trial 3 finished with value: 0.7894192892452073 and parameters: {'n_estimators': 1856, 'learning_rate': 0.037813057684555125, 'max_depth': 3, 'subsample': 0.9439121684415995, 'colsample_bytree': 0.7534096987845887, 'reg_alpha': 1.9589274444279126e-05, 'reg_lambda': 0.4370497693497897}. Best is trial 2 with value: 0.7769213264962144.\n",
      "[I 2026-02-12 19:49:11,347] Trial 4 finished with value: 0.7678503596331291 and parameters: {'n_estimators': 680, 'learning_rate': 0.06692732748166996, 'max_depth': 8, 'subsample': 0.8156985547966277, 'colsample_bytree': 0.6226022736607475, 'reg_alpha': 2.2557889348269315e-07, 'reg_lambda': 0.6379956929675095}. Best is trial 4 with value: 0.7678503596331291.\n",
      "[I 2026-02-12 19:49:25,229] Trial 5 finished with value: 0.7647829007163015 and parameters: {'n_estimators': 1837, 'learning_rate': 0.025159749169680685, 'max_depth': 8, 'subsample': 0.7890351309774649, 'colsample_bytree': 0.6244318039999263, 'reg_alpha': 1.1817973274125446e-08, 'reg_lambda': 0.0013984418823889627}. Best is trial 5 with value: 0.7647829007163015.\n",
      "[I 2026-02-12 19:49:34,951] Trial 6 finished with value: 0.7995132359849442 and parameters: {'n_estimators': 1851, 'learning_rate': 0.09164470011923379, 'max_depth': 8, 'subsample': 0.83074230557575, 'colsample_bytree': 0.7412033213254451, 'reg_alpha': 0.000975163610388757, 'reg_lambda': 0.0029235600279761058}. Best is trial 5 with value: 0.7647829007163015.\n",
      "[I 2026-02-12 19:49:36,152] Trial 7 finished with value: 0.7893540010024793 and parameters: {'n_estimators': 830, 'learning_rate': 0.04017552505246827, 'max_depth': 3, 'subsample': 0.9281798155195387, 'colsample_bytree': 0.7615303719323891, 'reg_alpha': 5.219586083532742e-05, 'reg_lambda': 0.00033609691562683485}. Best is trial 5 with value: 0.7647829007163015.\n",
      "[I 2026-02-12 19:49:40,618] Trial 8 finished with value: 0.7526366765257925 and parameters: {'n_estimators': 779, 'learning_rate': 0.0123423908100669, 'max_depth': 7, 'subsample': 0.9229101073683896, 'colsample_bytree': 0.799451794301056, 'reg_alpha': 5.345960509312979e-08, 'reg_lambda': 1.2945784624743641e-05}. Best is trial 8 with value: 0.7526366765257925.\n",
      "[I 2026-02-12 19:49:43,353] Trial 9 finished with value: 0.8043294212890876 and parameters: {'n_estimators': 1654, 'learning_rate': 0.07163288583286204, 'max_depth': 3, 'subsample': 0.7303405103942653, 'colsample_bytree': 0.9292444500220863, 'reg_alpha': 0.0002139626938199158, 'reg_lambda': 0.5237838238007154}. Best is trial 8 with value: 0.7526366765257925.\n",
      "[I 2026-02-12 19:49:48,309] Trial 10 finished with value: 0.7580131937452901 and parameters: {'n_estimators': 1167, 'learning_rate': 0.010437076380951066, 'max_depth': 6, 'subsample': 0.9863043584545239, 'colsample_bytree': 0.8453623444983565, 'reg_alpha': 0.19801415374535888, 'reg_lambda': 9.379089831076925e-07}. Best is trial 8 with value: 0.7526366765257925.\n",
      "[I 2026-02-12 19:49:53,378] Trial 11 finished with value: 0.7355316275551712 and parameters: {'n_estimators': 1119, 'learning_rate': 0.005708142946328598, 'max_depth': 6, 'subsample': 0.9982950442677259, 'colsample_bytree': 0.8511420570671421, 'reg_alpha': 1.8063854820447551, 'reg_lambda': 7.453741596742887e-07}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:49:56,633] Trial 12 finished with value: 0.7402909098094798 and parameters: {'n_estimators': 1069, 'learning_rate': 0.005661973689170796, 'max_depth': 5, 'subsample': 0.9999428103525246, 'colsample_bytree': 0.8365689327863666, 'reg_alpha': 0.3501588551769656, 'reg_lambda': 3.5743466732233825e-06}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:00,445] Trial 13 finished with value: 0.7367882717495772 and parameters: {'n_estimators': 1162, 'learning_rate': 0.007557486883998134, 'max_depth': 5, 'subsample': 0.9843969196026966, 'colsample_bytree': 0.9909053725151196, 'reg_alpha': 3.8132633570159844, 'reg_lambda': 1.0025996027212805e-08}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:05,203] Trial 14 finished with value: 0.7518165812184915 and parameters: {'n_estimators': 1414, 'learning_rate': 0.019770897266038687, 'max_depth': 5, 'subsample': 0.887331815634711, 'colsample_bytree': 0.9727791118406348, 'reg_alpha': 2.3471119350910117, 'reg_lambda': 1.4462851801278898e-08}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:11,603] Trial 15 finished with value: 0.8062180585445754 and parameters: {'n_estimators': 1370, 'learning_rate': 0.04925621510277467, 'max_depth': 6, 'subsample': 0.6008017860344291, 'colsample_bytree': 0.9983690073529462, 'reg_alpha': 0.034487455420931575, 'reg_lambda': 1.9023224140795966e-07}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:13,761] Trial 16 finished with value: 0.7380359540792226 and parameters: {'n_estimators': 1016, 'learning_rate': 0.016937015902376847, 'max_depth': 4, 'subsample': 0.8755978865321035, 'colsample_bytree': 0.6731117645504033, 'reg_alpha': 5.2608842283240485, 'reg_lambda': 2.0324858927061227e-07}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:25,300] Trial 17 finished with value: 0.7497099505553276 and parameters: {'n_estimators': 537, 'learning_rate': 0.005739865018505141, 'max_depth': 10, 'subsample': 0.9687712578153178, 'colsample_bytree': 0.8831803361934574, 'reg_alpha': 0.014045482530793988, 'reg_lambda': 5.186112501416983e-05}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:34,340] Trial 18 finished with value: 0.815077594912788 and parameters: {'n_estimators': 1363, 'learning_rate': 0.09872879187961087, 'max_depth': 7, 'subsample': 0.8856840678778557, 'colsample_bytree': 0.9535676251102148, 'reg_alpha': 0.0027785433320412518, 'reg_lambda': 9.528022133337501e-08}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:36,463] Trial 19 finished with value: 0.7397977073852781 and parameters: {'n_estimators': 998, 'learning_rate': 0.021544202691457324, 'max_depth': 4, 'subsample': 0.9401932288502071, 'colsample_bytree': 0.8718315563027762, 'reg_alpha': 8.348215073200876, 'reg_lambda': 9.845220269175506}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:43,135] Trial 20 finished with value: 0.7764645018792456 and parameters: {'n_estimators': 1479, 'learning_rate': 0.04550453916647033, 'max_depth': 6, 'subsample': 0.7579387989149285, 'colsample_bytree': 0.8214689040218327, 'reg_alpha': 0.4316924681070021, 'reg_lambda': 1.6916838307455754e-06}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:45,064] Trial 21 finished with value: 0.7368709018443385 and parameters: {'n_estimators': 984, 'learning_rate': 0.016933061311138767, 'max_depth': 4, 'subsample': 0.889516834886667, 'colsample_bytree': 0.6785642219523111, 'reg_alpha': 7.618220546456192, 'reg_lambda': 2.4406397087778197e-07}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:46,884] Trial 22 finished with value: 0.7398864145387919 and parameters: {'n_estimators': 925, 'learning_rate': 0.014983660768661283, 'max_depth': 4, 'subsample': 0.9606652398669531, 'colsample_bytree': 0.6843032827099371, 'reg_alpha': 0.9257140631387138, 'reg_lambda': 1.36822014037639e-08}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:50,054] Trial 23 finished with value: 0.7700647441178293 and parameters: {'n_estimators': 1197, 'learning_rate': 0.025636703883897754, 'max_depth': 5, 'subsample': 0.9008116444887444, 'colsample_bytree': 0.6949265064465479, 'reg_alpha': 0.06420047716197069, 'reg_lambda': 4.879301526870815e-07}. Best is trial 11 with value: 0.7355316275551712.\n",
      "[I 2026-02-12 19:50:52,585] Trial 24 finished with value: 0.7304675460685033 and parameters: {'n_estimators': 1237, 'learning_rate': 0.00501793138813654, 'max_depth': 4, 'subsample': 0.9943896953203759, 'colsample_bytree': 0.6525158402344471, 'reg_alpha': 1.6903236849704741, 'reg_lambda': 1.19992574695904e-07}. Best is trial 24 with value: 0.7304675460685033.\n",
      "[I 2026-02-12 19:50:57,627] Trial 25 finished with value: 0.7509907993156973 and parameters: {'n_estimators': 1279, 'learning_rate': 0.005697565772507479, 'max_depth': 6, 'subsample': 0.9953859932786062, 'colsample_bytree': 0.7878572245393409, 'reg_alpha': 0.0050267216797124014, 'reg_lambda': 4.2066763450025974e-08}. Best is trial 24 with value: 0.7304675460685033.\n",
      "[I 2026-02-12 19:51:02,699] Trial 26 finished with value: 0.7844773268671306 and parameters: {'n_estimators': 1517, 'learning_rate': 0.06324617495346209, 'max_depth': 5, 'subsample': 0.9691075822222763, 'colsample_bytree': 0.9124239004254787, 'reg_alpha': 1.2447806502592573, 'reg_lambda': 9.74899007966925e-05}. Best is trial 24 with value: 0.7304675460685033.\n",
      "[I 2026-02-12 19:51:09,612] Trial 27 finished with value: 0.7813849245813266 and parameters: {'n_estimators': 1155, 'learning_rate': 0.033156078615666607, 'max_depth': 7, 'subsample': 0.9176528867579532, 'colsample_bytree': 0.859037962516554, 'reg_alpha': 3.3057088864312615e-06, 'reg_lambda': 4.428971744244032e-06}. Best is trial 24 with value: 0.7304675460685033.\n",
      "[I 2026-02-12 19:51:13,494] Trial 28 finished with value: 0.7563789503895803 and parameters: {'n_estimators': 1998, 'learning_rate': 0.009926359881103254, 'max_depth': 4, 'subsample': 0.8617914207949984, 'colsample_bytree': 0.6495498769114681, 'reg_alpha': 0.10596278489401918, 'reg_lambda': 6.58588137508631e-08}. Best is trial 24 with value: 0.7304675460685033.\n",
      "[I 2026-02-12 19:51:26,289] Trial 29 finished with value: 0.7773247623368058 and parameters: {'n_estimators': 1307, 'learning_rate': 0.08225994919394661, 'max_depth': 9, 'subsample': 0.6709191120574899, 'colsample_bytree': 0.7196234171824091, 'reg_alpha': 0.02726645312389129, 'reg_lambda': 0.028389221638519823}. Best is trial 24 with value: 0.7304675460685033.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------\n",
      "ðŸŽ‰ BEST RMSE FOUND: 0.7304675460685033\n",
      "ðŸ‘‰ COPY THESE PARAMS FOR SCRIPT 3:\n",
      "{'n_estimators': 1237, 'learning_rate': 0.00501793138813654, 'max_depth': 4, 'subsample': 0.9943896953203759, 'colsample_bytree': 0.6525158402344471, 'reg_alpha': 1.6903236849704741, 'reg_lambda': 1.19992574695904e-07}\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# fine tuning parameters for better performance\n",
    "\n",
    "import optuna\n",
    "import re\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "# Basic Preprocessing\n",
    "def simple_process(df):\n",
    "    df['Size_Log'] = np.log1p(df['Size'])\n",
    "    df['Desc_Len'] = df['Description'].fillna('').apply(len)\n",
    "    df['Lang_Count'] = df['Languages'].apply(lambda x: len(str(x).split(',')) if pd.notnull(x) else 0)\n",
    "    \n",
    "    # Date Engineering\n",
    "    df['Original Release Date'] = pd.to_datetime(df['Original Release Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    df['Current Version Release Date'] = pd.to_datetime(df['Current Version Release Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    ref_date = pd.to_datetime('today')\n",
    "    df['Days_Since_Update'] = (ref_date - df['Current Version Release Date']).dt.days\n",
    "    df['App_Age_Days'] = (ref_date - df['Original Release Date']).dt.days\n",
    "    \n",
    "    # Select only numeric\n",
    "    df = df.select_dtypes(include=['number', 'bool'])\n",
    "    df = df.rename(columns = lambda x: re.sub('[^A-Za-z0-9_]+', '', x)) # Clean names\n",
    "    return df.fillna(0)\n",
    "\n",
    "X = simple_process(df_train.drop(columns=['Average User Rating']))\n",
    "y = df_train['Average User Rating']\n",
    "\n",
    "# --- 2. OPTUNA OPTIMIZATION ---\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(**param)\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring='neg_root_mean_squared_error')\n",
    "    return -scores.mean()\n",
    "\n",
    "print(\"Starting Optimization... (This might take 5-10 mins)\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"ðŸŽ‰ BEST RMSE FOUND:\", study.best_value)\n",
    "print(\"ðŸ‘‰ COPY THESE PARAMS FOR SCRIPT 3:\")\n",
    "print(study.best_params)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e0872602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-12 20:08:49,934] A new study created in memory with name: no-name-e6f486d7-1e84-43d0-97d5-dcf8bed41d3a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optimization... (This might take 5-10 mins)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-12 20:08:54,948] Trial 0 finished with value: 0.812235979886525 and parameters: {'n_estimators': 1567, 'learning_rate': 0.07070352183547696, 'max_depth': 8, 'num_leaves': 103}. Best is trial 0 with value: 0.812235979886525.\n",
      "[I 2026-02-12 20:08:58,717] Trial 1 finished with value: 0.8256637500019671 and parameters: {'n_estimators': 1786, 'learning_rate': 0.07536554569541994, 'max_depth': 6, 'num_leaves': 26}. Best is trial 0 with value: 0.812235979886525.\n",
      "[I 2026-02-12 20:09:02,352] Trial 2 finished with value: 0.7816633789459612 and parameters: {'n_estimators': 1551, 'learning_rate': 0.03151465180224943, 'max_depth': 6, 'num_leaves': 123}. Best is trial 2 with value: 0.7816633789459612.\n",
      "[I 2026-02-12 20:09:05,882] Trial 3 finished with value: 0.7978527106925094 and parameters: {'n_estimators': 1329, 'learning_rate': 0.06111973817446609, 'max_depth': 7, 'num_leaves': 56}. Best is trial 2 with value: 0.7816633789459612.\n",
      "[I 2026-02-12 20:09:07,045] Trial 4 finished with value: 0.754881377235605 and parameters: {'n_estimators': 1203, 'learning_rate': 0.03512496977526164, 'max_depth': 3, 'num_leaves': 27}. Best is trial 4 with value: 0.754881377235605.\n",
      "[I 2026-02-12 20:09:10,012] Trial 5 finished with value: 0.7933626537347744 and parameters: {'n_estimators': 1070, 'learning_rate': 0.05601963304926157, 'max_depth': 7, 'num_leaves': 134}. Best is trial 4 with value: 0.754881377235605.\n",
      "[I 2026-02-12 20:09:11,660] Trial 6 finished with value: 0.787655957713643 and parameters: {'n_estimators': 594, 'learning_rate': 0.0672347297493444, 'max_depth': 7, 'num_leaves': 51}. Best is trial 4 with value: 0.754881377235605.\n",
      "[I 2026-02-12 20:09:13,202] Trial 7 finished with value: 0.7925963425127772 and parameters: {'n_estimators': 1049, 'learning_rate': 0.08044715768860969, 'max_depth': 4, 'num_leaves': 23}. Best is trial 4 with value: 0.754881377235605.\n",
      "[I 2026-02-12 20:09:14,799] Trial 8 finished with value: 0.743935092106495 and parameters: {'n_estimators': 1575, 'learning_rate': 0.011957039914727036, 'max_depth': 3, 'num_leaves': 88}. Best is trial 8 with value: 0.743935092106495.\n",
      "[I 2026-02-12 20:09:17,369] Trial 9 finished with value: 0.8146487640733087 and parameters: {'n_estimators': 1845, 'learning_rate': 0.09891742002726574, 'max_depth': 4, 'num_leaves': 121}. Best is trial 8 with value: 0.743935092106495.\n",
      "[I 2026-02-12 20:09:18,100] Trial 10 finished with value: 0.7376884711290104 and parameters: {'n_estimators': 718, 'learning_rate': 0.013303987783920617, 'max_depth': 3, 'num_leaves': 84}. Best is trial 10 with value: 0.7376884711290104.\n",
      "[I 2026-02-12 20:09:21,456] Trial 11 finished with value: 0.7500165945532976 and parameters: {'n_estimators': 558, 'learning_rate': 0.00812155658369109, 'max_depth': 10, 'num_leaves': 81}. Best is trial 10 with value: 0.7376884711290104.\n",
      "[I 2026-02-12 20:09:22,450] Trial 12 finished with value: 0.7355958373545227 and parameters: {'n_estimators': 872, 'learning_rate': 0.005160487761380096, 'max_depth': 3, 'num_leaves': 86}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:24,119] Trial 13 finished with value: 0.7576681213441421 and parameters: {'n_estimators': 871, 'learning_rate': 0.025279577248364632, 'max_depth': 5, 'num_leaves': 74}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:25,272] Trial 14 finished with value: 0.7449370073789732 and parameters: {'n_estimators': 809, 'learning_rate': 0.018343333041010865, 'max_depth': 4, 'num_leaves': 101}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:26,045] Trial 15 finished with value: 0.7507184749144611 and parameters: {'n_estimators': 786, 'learning_rate': 0.04005261435450566, 'max_depth': 3, 'num_leaves': 57}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:27,347] Trial 16 finished with value: 0.7685158423010675 and parameters: {'n_estimators': 691, 'learning_rate': 0.046688395359196236, 'max_depth': 5, 'num_leaves': 99}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:33,077] Trial 17 finished with value: 0.7472678593390366 and parameters: {'n_estimators': 965, 'learning_rate': 0.005245820522731319, 'max_depth': 9, 'num_leaves': 150}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:35,458] Trial 18 finished with value: 0.7597402504213041 and parameters: {'n_estimators': 1261, 'learning_rate': 0.019743190778770535, 'max_depth': 5, 'num_leaves': 70}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:35,971] Trial 19 finished with value: 0.7409064787442814 and parameters: {'n_estimators': 504, 'learning_rate': 0.024989457267530366, 'max_depth': 3, 'num_leaves': 42}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:36,963] Trial 20 finished with value: 0.7427717952266631 and parameters: {'n_estimators': 694, 'learning_rate': 0.017609113718224226, 'max_depth': 4, 'num_leaves': 90}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:37,472] Trial 21 finished with value: 0.7413064790094811 and parameters: {'n_estimators': 500, 'learning_rate': 0.029079134396763583, 'max_depth': 3, 'num_leaves': 40}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:38,154] Trial 22 finished with value: 0.7373242556503091 and parameters: {'n_estimators': 674, 'learning_rate': 0.013467658844598732, 'max_depth': 3, 'num_leaves': 67}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:39,523] Trial 23 finished with value: 0.74236282798359 and parameters: {'n_estimators': 915, 'learning_rate': 0.0117848656379104, 'max_depth': 4, 'num_leaves': 63}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:41,257] Trial 24 finished with value: 0.7368108841964022 and parameters: {'n_estimators': 724, 'learning_rate': 0.005375076921834922, 'max_depth': 5, 'num_leaves': 79}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:43,810] Trial 25 finished with value: 0.7398514691327606 and parameters: {'n_estimators': 1087, 'learning_rate': 0.0050432983894158154, 'max_depth': 5, 'num_leaves': 71}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:45,404] Trial 26 finished with value: 0.7725276992219469 and parameters: {'n_estimators': 665, 'learning_rate': 0.04269201692594687, 'max_depth': 6, 'num_leaves': 95}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:46,551] Trial 27 finished with value: 0.7468630202968077 and parameters: {'n_estimators': 811, 'learning_rate': 0.021076701677630996, 'max_depth': 4, 'num_leaves': 111}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:48,439] Trial 28 finished with value: 0.746165249460975 and parameters: {'n_estimators': 932, 'learning_rate': 0.012989451331438332, 'max_depth': 5, 'num_leaves': 67}. Best is trial 12 with value: 0.7355958373545227.\n",
      "[I 2026-02-12 20:09:50,076] Trial 29 finished with value: 0.7606991642540223 and parameters: {'n_estimators': 1154, 'learning_rate': 0.03577726666175381, 'max_depth': 4, 'num_leaves': 110}. Best is trial 12 with value: 0.7355958373545227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------\n",
      "ðŸŽ‰ BEST RMSE FOUND: 0.7355958373545227\n",
      "ðŸ‘‰ COPY THESE PARAMS FOR SCRIPT 3:\n",
      "{'n_estimators': 872, 'learning_rate': 0.005160487761380096, 'max_depth': 3, 'num_leaves': 86}\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# fine tuning parameters for better performance\n",
    "\n",
    "import optuna\n",
    "import re\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "# Basic Preprocessing\n",
    "def simple_process(df):\n",
    "    df['Size_Log'] = np.log1p(df['Size'])\n",
    "    df['Desc_Len'] = df['Description'].fillna('').apply(len)\n",
    "    df['Lang_Count'] = df['Languages'].apply(lambda x: len(str(x).split(',')) if pd.notnull(x) else 0)\n",
    "    \n",
    "    # Date Engineering\n",
    "    df['Original Release Date'] = pd.to_datetime(df['Original Release Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    df['Current Version Release Date'] = pd.to_datetime(df['Current Version Release Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    ref_date = pd.to_datetime('today')\n",
    "    df['Days_Since_Update'] = (ref_date - df['Current Version Release Date']).dt.days\n",
    "    df['App_Age_Days'] = (ref_date - df['Original Release Date']).dt.days\n",
    "    \n",
    "    # Select only numeric\n",
    "    df = df.select_dtypes(include=['number', 'bool'])\n",
    "    df = df.rename(columns = lambda x: re.sub('[^A-Za-z0-9_]+', '', x)) # Clean names\n",
    "    return df.fillna(0)\n",
    "\n",
    "X = simple_process(df_train.drop(columns=['Average User Rating']))\n",
    "y = df_train['Average User Rating']\n",
    "\n",
    "# --- 2. OPTUNA OPTIMIZATION ---\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    model = LGBMRegressor(**param)\n",
    "    scores = cross_val_score(model, X, y, cv=3, scoring='neg_root_mean_squared_error')\n",
    "    return -scores.mean()\n",
    "\n",
    "print(\"Starting Optimization... (This might take 5-10 mins)\")\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"ðŸŽ‰ BEST RMSE FOUND:\", study.best_value)\n",
    "print(\"ðŸ‘‰ COPY THESE PARAMS FOR SCRIPT 3:\")\n",
    "print(study.best_params)\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7af3ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. MODELING (Ensemble) ---\n",
    "\n",
    "# Initialize Models\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=1000, \n",
    "    learning_rate=0.01, \n",
    "    max_depth=3, \n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# Ensemble Voting Regressor (Averages the predictions of both)\n",
    "ensemble = VotingRegressor([('xgb', xgb), ('lgbm', lgbm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf8b71f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 0.7165\n"
     ]
    }
   ],
   "source": [
    "# --- 4. VALIDATION ---\n",
    "# Use Cross-Validation to get a realistic RMSE\n",
    "scores = cross_val_score(ensemble, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Average RMSE: {-scores.mean():.4f}\")\n",
    "\n",
    "# --- 5. FINAL TRAINING & SUBMISSION ---\n",
    "ensemble.fit(X_processed, y)\n",
    "preds = ensemble.predict(test_processed)\n",
    "\n",
    "# Post-processing: Clip predictions to be between 0 and 5\n",
    "preds = np.clip(preds, 0.0, 5.0)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': preds})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c72d4106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average RMSE: 0.7146\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=1000,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "scores_rf = cross_val_score(rf_model, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Random Forest Average RMSE: {-scores_rf.mean():.4f}\")\n",
    "\n",
    "rf_model.fit(X_processed, y)\n",
    "rf_preds = rf_model.predict(test_processed)\n",
    "rf_preds = np.clip(rf_preds, 0.0, 5.0)\n",
    "submission_rf = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': rf_preds})\n",
    "submission_rf.to_csv('submission_rf.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e8e8a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average RMSE: 0.7150\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=3000,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "scores_rf = cross_val_score(rf_model, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Random Forest Average RMSE: {-scores_rf.mean():.4f}\")\n",
    "\n",
    "rf_model.fit(X_processed, y)\n",
    "rf_preds = rf_model.predict(test_processed)\n",
    "rf_preds = np.clip(rf_preds, 0.0, 5.0)\n",
    "submission_rf = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': rf_preds})\n",
    "submission_rf.to_csv('submission_rf.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "785dbf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Average RMSE: 0.8329\n"
     ]
    }
   ],
   "source": [
    "# decisin tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_model = DecisionTreeRegressor(\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "scores_dt = cross_val_score(dt_model, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Decision Tree Average RMSE: {-scores_dt.mean():.4f}\")\n",
    "\n",
    "dt_model.fit(X_processed, y)\n",
    "dt_preds = dt_model.predict(test_processed)\n",
    "dt_preds = np.clip(dt_preds, 0.0, 5.0)\n",
    "submission_dt = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': dt_preds})\n",
    "submission_dt.to_csv('submission_dt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "88d614a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Average RMSE: 0.7485\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "scores_svr = cross_val_score(svr_model, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"SVR Average RMSE: {-scores_svr.mean():.4f}\")\n",
    "svr_model.fit(X_processed, y)\n",
    "svr_preds = svr_model.predict(test_processed)\n",
    "svr_preds = np.clip(svr_preds, 0.0, 5.0)\n",
    "submission_svr = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': svr_preds})\n",
    "submission_svr.to_csv('submission_svr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c972ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix Nans in test set\n",
    "test_processed = test_processed.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "35b6431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Average RMSE: 0.7285\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "scores_lr = cross_val_score(lr_model, X_processed, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Linear Regression Average RMSE: {-scores_lr.mean():.4f}\")\n",
    "lr_model.fit(X_processed, y)\n",
    "lr_preds = lr_model.predict(test_processed)\n",
    "lr_preds = np.clip(lr_preds, 0.0, 5.0)\n",
    "submission_lr = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': lr_preds})\n",
    "submission_lr.to_csv('submission_lr.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "972bd1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression Average RMSE: 5.5078\n"
     ]
    }
   ],
   "source": [
    "# polynomial regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3, interaction_only=True, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_processed)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "poly_model = LinearRegression()\n",
    "scores_poly = cross_val_score(poly_model, X_poly, y, scoring='neg_root_mean_squared_error', cv=5)\n",
    "print(f\"Polynomial Regression Average RMSE: {-scores_poly.mean():.4f}\")\n",
    "poly_model.fit(X_poly, y)\n",
    "test_poly = poly.transform(test_processed)\n",
    "poly_preds = poly_model.predict(test_poly)\n",
    "poly_preds = np.clip(poly_preds, 0.0, 5.0)\n",
    "submission_poly = pd.DataFrame({'ID': df_test['ID'], 'Average User Rating': poly_preds})\n",
    "submission_poly.to_csv('submission_poly.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
